{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv ('comment_train.csv')\n",
    "test_data = pd.read_csv ('comment_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_train = train_data[(train_data['recommend'] == 'recommended')]\n",
    "recommend_count = recommend_train.count()['title']\n",
    "not_recommend_train = train_data[(train_data['recommend'] == 'not_recommended')]\n",
    "not_recommend_count = not_recommend_train.count()['title']\n",
    "\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def normalize_str(str):\n",
    "    data = []\n",
    "    normalizer = Normalizer()\n",
    "    data = word_tokenize(normalizer.normalize(str))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i] = lemmatizer.lemmatize(stemmer.stem(data[i]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq(data):\n",
    "    count = dict(collections.Counter(data))\n",
    "    return count    \n",
    "\n",
    "def normalize_data(flag):    \n",
    "    rec_words = []\n",
    "    not_rec_words = []\n",
    "\n",
    "    for index,row in recommend_train.iterrows():\n",
    "        if flag == 1: rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    for index,row in not_recommend_train.iterrows():\n",
    "        if flag == 1: not_rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: not_rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    rec_data = calc_freq(rec_words)\n",
    "    not_rec_data = calc_freq(not_rec_words)\n",
    "\n",
    "    test = test_data.copy()\n",
    "\n",
    "    for index,row in test.iterrows():\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            if i not in rec_data: rec_data[i] = 0\n",
    "            if i not in not_rec_data: not_rec_data[i] = 0\n",
    "                \n",
    "    return rec_data,not_rec_data,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_smoothing(rec_data,not_rec_data):\n",
    "    rec = {}\n",
    "    not_rec = {}\n",
    "    for i in rec_data:\n",
    "        rec[i] = rec_data[i] + 1\n",
    "    for i in not_rec_data:\n",
    "        not_rec[i] = not_rec_data[i] + 1\n",
    "    return rec, not_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dict(dic):\n",
    "    sum = 0\n",
    "    for i in dic: \n",
    "        sum = sum + dic[i]\n",
    "    return sum\n",
    "\n",
    "def rec_or_not(test_,rec_data,not_rec_data,flag):\n",
    "    rec_words_count = sum_dict(rec_data)\n",
    "    not_rec_words_count = sum_dict(not_rec_data)\n",
    "    for index,row in test_.iterrows():\n",
    "        rec_prob = recommend_count/(recommend_count+not_recommend_count)\n",
    "        not_rec_prob = not_recommend_count/(recommend_count+not_recommend_count)\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            rec_prob *= (rec_data[i]/rec_words_count)\n",
    "            not_rec_prob *= (not_rec_data[i]/not_rec_words_count)\n",
    "            if rec_prob >= not_rec_prob: row['recommend'] = 'recommended'\n",
    "            else: row['recommend'] = 'not_recommended'\n",
    "    return test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test):\n",
    "    wrong = []\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] : right += 1\n",
    "        else: wrong.append((test['title'][i],test['comment'][i],test['recommend'][i]))\n",
    "    return right/test.count()['title'],wrong\n",
    "\n",
    "def precision(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test[(test['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def recall(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test_data[(test_data['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def f1(pre,rec):\n",
    "    return (2*pre*rec)/(pre+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process and additive smoothing:\n",
      "accuracy :  0.9175\n",
      "precision:  0.8938679245283019\n",
      "recall :  0.9475\n",
      "F1 :  0.9199029126213593\n"
     ]
    }
   ],
   "source": [
    "#pre process and additive smoothing\n",
    "rec_data_1,not_rec_data_1,test_1 = normalize_data(1)\n",
    "\n",
    "both_rec, both_not_rec = additive_smoothing(rec_data_1,not_rec_data_1)\n",
    "\n",
    "filled_test_both = rec_or_not(test_1,both_rec,both_not_rec,1)\n",
    "\n",
    "acc_1,wrong = accuracy(filled_test_both)\n",
    "prec_1 = precision(filled_test_both)\n",
    "rec_1 = recall(filled_test_both)\n",
    "f1_1 = f1(prec_1,rec_1)\n",
    "\n",
    "print(\"pre process and additive smoothing:\")\n",
    "print (\"accuracy : \",acc_1)\n",
    "print (\"precision: \",prec_1)\n",
    "print (\"recall : \",rec_1)\n",
    "print (\"F1 : \",f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additive smoothing:\n",
      "accuracy :  0.91375\n",
      "precision:  0.8857808857808858\n",
      "recall :  0.95\n",
      "F1 :  0.916767189384801\n"
     ]
    }
   ],
   "source": [
    "#additive smoothing\n",
    "rec_data_2,not_rec_data_2,test_2 = normalize_data(0)\n",
    "\n",
    "additive_rec, additive_not_rec = additive_smoothing(rec_data_2,not_rec_data_2)\n",
    "\n",
    "filled_test_additive = rec_or_not(test_2,additive_rec,additive_not_rec,0)\n",
    "\n",
    "acc_2,r = accuracy(filled_test_additive)\n",
    "prec_2 = precision(filled_test_additive)\n",
    "rec_2 = recall(filled_test_additive)\n",
    "f1_2 = f1(prec_2,rec_2)\n",
    "\n",
    "print(\"additive smoothing:\")\n",
    "print (\"accuracy : \",acc_2)\n",
    "print (\"precision: \",prec_2)\n",
    "print (\"recall : \",rec_2)\n",
    "print (\"F1 : \",f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process:\n",
      "accuracy :  0.86\n",
      "precision:  0.7950819672131147\n",
      "recall :  0.97\n",
      "F1 :  0.8738738738738738\n"
     ]
    }
   ],
   "source": [
    "#pre process\n",
    "rec_data_3,not_rec_data_3,test_3 = normalize_data(1)\n",
    "\n",
    "filled_test_pre = rec_or_not(test_3,rec_data_3,not_rec_data_3,1)\n",
    "\n",
    "acc_3,r = accuracy(filled_test_pre)\n",
    "prec_3 = precision(filled_test_pre)\n",
    "rec_3 = recall(filled_test_pre)\n",
    "f1_3 = f1(prec_3,rec_3)\n",
    "\n",
    "print(\"pre process:\")\n",
    "print (\"accuracy : \",acc_3)\n",
    "print (\"precision: \",prec_3)\n",
    "print (\"recall : \",rec_3)\n",
    "print (\"F1 : \",f1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none:\n",
      "accuracy :  0.85625\n",
      "precision:  0.7844311377245509\n",
      "recall :  0.9825\n",
      "F1 :  0.872364039955605\n"
     ]
    }
   ],
   "source": [
    "#none\n",
    "rec_data_4,not_rec_data_4,test_4 = normalize_data(0)\n",
    "\n",
    "filled_test_none = rec_or_not(test_4,rec_data_4,not_rec_data_4,0)\n",
    "\n",
    "acc_4,r = accuracy(filled_test_none)\n",
    "prec_4 = precision(filled_test_none)\n",
    "rec_4 = recall(filled_test_none)\n",
    "f1_4 = f1(prec_4,rec_4)\n",
    "\n",
    "print(\"none:\")\n",
    "print (\"accuracy : \",acc_4)\n",
    "print (\"precision: \",prec_4)\n",
    "print (\"recall : \",rec_4)\n",
    "print (\"F1 : \",f1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not_recommended',\n",
       "  'وری گود',\n",
       "  'تازه خریدم یه مدت کار بکنه مشخص میشه کیفیت قطعاتش'),\n",
       " ('recommended',\n",
       "  'دستگاه خیلی ضعیف',\n",
       "  'من این فیس براس چند روز یپش به دستم رسید و الان بعد از چند روز استفاده از همه سری هاش دارم نظرم رو مینویسم\\r\\nاول تشکر کنم بابت ارسال و بسته بندیه خوب دیجیکالا \\r\\nو اینکه این فیس براش رو من توی تخفیف خریدم. اول اینکه دستگاه به شدت ضعیفه با اینکه من 4تا باطری خوب هم انداختم روش ولی بازم خیلی ضعیفه در حدی که زود خاموش میشه! برس صورتش به نظر من باید لطیف تر باشه و برعکس برس بدنش باید یکم زبر تر باشه که بتونه لایه برداری انجام بده ولی برای شستشو معمولی بدن بد نیست ولی خب انقد ضعیفه که نمیشه باهاش شست. من تصمیم دارم بازش کنم و خودم قوی ترش کنم امیدوارم اون موقع بهتر بشه. در کل بنظر من بد حد یه فیس براش دستیه ولی آدم پولش رو جمع کنه و یه بهترش رو بخره خیلی بهتره چون این حتی سری هاشم گیر نمیاد و وقتی سری ها خراب بشن دیگه قابل استفاده نیست..'),\n",
       " ('recommended',\n",
       "  'خوب ولی کارایی محدود',\n",
       "  'مدل 46MM به دست شما نخواهد رسید و به جای آن مدل 35MM برای شما ارسال خواهد شد که چسب پهن در آن جا نمیگیرد. جالب این که در روی جعبه هم به دروغ جلو 46MM تیک زده! چسب پهن های موجود در بازار عرض 46 میلیمتر دارند ولی پهن ترین چسبی که در این پایه جا میگیرد 35 میلیمتر چون اصلا مدل 35MM برای شما ارسال خواهد شد. در توضیحات برای توجیه مدل 46 ادعا شده است که چسب ها را به طول 46 میلی متر برش میزند در حالی که اصلا مدل 46 به آن ربطی ندارد و دستگاه چسب ها را به طول 5 سانتیمتر یعنی 50 میلیمتر برش میزند.\\r\\nولی نکته مثبت آن این است که چسب ها را به خوبی و خیلی جالب در اندازه های ثابت و خیلی سریع تکه میکند و بهترین کاربرد آن برای کسانی است که زیاد بسته بندی کادویی انجام میدهند.'),\n",
       " ('not_recommended',\n",
       "  'نقد پس از خرید',\n",
       "  'سلام ، راحت شدم از کابل شارژ ، توصیه میشود به شدت . ارزان گوشی خود را به شارژ وایرلس مجهز کنید .'),\n",
       " ('recommended',\n",
       "  'نقد منصفانه',\n",
       "  'من تو تخفیف ویژه 5 تا خریدم و همشون رو هم تست کردم و اینکه میگن دوستان که خرابه برای من پیش نیومده\\r\\nانتقال فایل هم میشه با کامپیوتر اونم مشکلی ندارن\\r\\nشارژ سریعشم تست کردم اونم اوکی هست (دوستان اینکه کابل فقط شارش سریع باشه کافی نیست برای اینکه گوشیتون سریع شارژ بشه , کلگی شارژ و خود گوشی هم باید قابلیت شارژ سریع رو هم داشته باشه)\\r\\nفقط تنها مشکل اینکه جنس خود سیم یکم بی کیفیت هست و امیدوارم پاره نشن \\r\\nبرای مدت عمرش فقط کوتاهست بین 1 تا 3 ماه بیشتر دوام نداره البته یکیش یک هفته هم دوام نیاورد\\r\\nدر ضمن این کابلها طرح خوب هستن و فابریک سامسونگ نیستن')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wrong, columns =['title', 'comment', 'recommend']) \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
