{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv ('comment_train.csv')\n",
    "test_data = pd.read_csv ('comment_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_train = train_data[(train_data['recommend'] == 'recommended')]\n",
    "recommend_count = recommend_train.count()['title']\n",
    "not_recommend_train = train_data[(train_data['recommend'] == 'not_recommended')]\n",
    "not_recommend_count = not_recommend_train.count()['title']\n",
    "\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def normalize_str(str):\n",
    "    data = []\n",
    "    normalizer = Normalizer()\n",
    "    data = word_tokenize(normalizer.normalize(str))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i] = lemmatizer.lemmatize(stemmer.stem(data[i]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq(data):\n",
    "    count = dict(collections.Counter(data))\n",
    "    return count    \n",
    "\n",
    "def normalize_data(flag):    \n",
    "    rec_words = []\n",
    "    not_rec_words = []\n",
    "\n",
    "    for index,row in recommend_train.iterrows():\n",
    "        if flag == 1: rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    for index,row in not_recommend_train.iterrows():\n",
    "        if flag == 1: not_rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: not_rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    rec_data = calc_freq(rec_words)\n",
    "    not_rec_data = calc_freq(not_rec_words)\n",
    "\n",
    "    test = test_data.copy()\n",
    "\n",
    "    for index,row in test.iterrows():\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            if i not in rec_data: rec_data[i] = 0\n",
    "            if i not in not_rec_data: not_rec_data[i] = 0\n",
    "                \n",
    "    return rec_data,not_rec_data,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_smoothing(rec_data,not_rec_data):\n",
    "    rec = {}\n",
    "    not_rec = {}\n",
    "    for i in rec_data:\n",
    "        rec[i] = rec_data[i] + 1\n",
    "    for i in not_rec_data:\n",
    "        not_rec[i] = not_rec_data[i] + 1\n",
    "    return rec, not_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dict(dic):\n",
    "    sum = 0\n",
    "    for i in dic: \n",
    "        sum = sum + dic[i]\n",
    "    return sum\n",
    "\n",
    "def rec_or_not(test_,rec_data,not_rec_data,flag):\n",
    "    rec_words_count = sum_dict(rec_data)\n",
    "    not_rec_words_count = sum_dict(not_rec_data)\n",
    "    for index,row in test_.iterrows():\n",
    "        rec_prob = recommend_count/(recommend_count+not_recommend_count)\n",
    "        not_rec_prob = not_recommend_count/(recommend_count+not_recommend_count)\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            rec_prob *= (rec_data[i]/rec_words_count)\n",
    "            not_rec_prob *= (not_rec_data[i]/not_rec_words_count)\n",
    "            if rec_prob >= not_rec_prob: row['recommend'] = 'recommended'\n",
    "            else: row['recommend'] = 'not_recommended'\n",
    "    return test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test):\n",
    "    wrong = []\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] : right += 1\n",
    "        else: wrong.append((test['title'][i],test['comment'][i],test['recommend'][i]))\n",
    "    return right/test.count()['title'],wrong\n",
    "\n",
    "def precision(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test[(test['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def recall(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test_data[(test_data['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def f1(pre,rec):\n",
    "    return (2*pre*rec)/(pre+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process and additive smoothing:\n",
      "accuracy :  0.9175\n",
      "precision:  0.8938679245283019\n",
      "recall :  0.9475\n",
      "F1 :  0.9199029126213593\n"
     ]
    }
   ],
   "source": [
    "#pre process and additive smoothing\n",
    "rec_data_1,not_rec_data_1,test_1 = normalize_data(1)\n",
    "\n",
    "both_rec, both_not_rec = additive_smoothing(rec_data_1,not_rec_data_1)\n",
    "\n",
    "filled_test_both = rec_or_not(test_1,both_rec,both_not_rec,1)\n",
    "\n",
    "acc_1,wrong = accuracy(filled_test_both)\n",
    "prec_1 = precision(filled_test_both)\n",
    "rec_1 = recall(filled_test_both)\n",
    "f1_1 = f1(prec_1,rec_1)\n",
    "\n",
    "print(\"pre process and additive smoothing:\")\n",
    "print (\"accuracy : \",acc_1)\n",
    "print (\"precision: \",prec_1)\n",
    "print (\"recall : \",rec_1)\n",
    "print (\"F1 : \",f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additive smoothing:\n",
      "accuracy :  0.91375\n",
      "precision:  0.8857808857808858\n",
      "recall :  0.95\n",
      "F1 :  0.916767189384801\n"
     ]
    }
   ],
   "source": [
    "#additive smoothing\n",
    "rec_data_2,not_rec_data_2,test_2 = normalize_data(0)\n",
    "\n",
    "additive_rec, additive_not_rec = additive_smoothing(rec_data_2,not_rec_data_2)\n",
    "\n",
    "filled_test_additive = rec_or_not(test_2,additive_rec,additive_not_rec,0)\n",
    "\n",
    "acc_2,r = accuracy(filled_test_additive)\n",
    "prec_2 = precision(filled_test_additive)\n",
    "rec_2 = recall(filled_test_additive)\n",
    "f1_2 = f1(prec_2,rec_2)\n",
    "\n",
    "print(\"additive smoothing:\")\n",
    "print (\"accuracy : \",acc_2)\n",
    "print (\"precision: \",prec_2)\n",
    "print (\"recall : \",rec_2)\n",
    "print (\"F1 : \",f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process\n",
    "rec_data_3,not_rec_data_3,test_3 = normalize_data(1)\n",
    "\n",
    "filled_test_pre = rec_or_not(test_3,rec_data_3,not_rec_data_3,1)\n",
    "\n",
    "acc_3,r = accuracy(filled_test_pre)\n",
    "prec_3 = precision(filled_test_pre)\n",
    "rec_3 = recall(filled_test_pre)\n",
    "f1_3 = f1(prec_3,rec_3)\n",
    "\n",
    "print(\"pre process:\")\n",
    "print (\"accuracy : \",acc_3)\n",
    "print (\"precision: \",prec_3)\n",
    "print (\"recall : \",rec_3)\n",
    "print (\"F1 : \",f1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#none\n",
    "rec_data_4,not_rec_data_4,test_4 = normalize_data(0)\n",
    "\n",
    "filled_test_none = rec_or_not(test_4,rec_data_4,not_rec_data_4,0)\n",
    "\n",
    "acc_4,r = accuracy(filled_test_none)\n",
    "prec_4 = precision(filled_test_none)\n",
    "rec_4 = recall(filled_test_none)\n",
    "f1_4 = f1(prec_4,rec_4)\n",
    "\n",
    "print(\"none:\")\n",
    "print (\"accuracy : \",acc_4)\n",
    "print (\"precision: \",prec_4)\n",
    "print (\"recall : \",rec_4)\n",
    "print (\"F1 : \",f1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wrong, columns =['title', 'comment', 'recommend']) \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
