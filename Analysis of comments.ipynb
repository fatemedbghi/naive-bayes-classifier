{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv ('comment_train.csv')\n",
    "test_data = pd.read_csv ('comment_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_train = train_data[(train_data['recommend'] == 'recommended')]\n",
    "recommend_count = recommend_train.count()['title']\n",
    "not_recommend_train = train_data[(train_data['recommend'] == 'not_recommended')]\n",
    "not_recommend_count = not_recommend_train.count()['title']\n",
    "\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def normalize_str(str):\n",
    "    data = []\n",
    "    normalizer = Normalizer()\n",
    "    data = word_tokenize(normalizer.normalize(str))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i] = lemmatizer.lemmatize(stemmer.stem(data[i]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_freq(data):\n",
    "    count = dict(collections.Counter(data))\n",
    "    return count    \n",
    "\n",
    "def normalize_data(flag):    \n",
    "    rec_words = []\n",
    "    not_rec_words = []\n",
    "\n",
    "    for index,row in recommend_train.iterrows():\n",
    "        if flag == 1: rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    for index,row in not_recommend_train.iterrows():\n",
    "        if flag == 1: not_rec_words += normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: not_rec_words += word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        \n",
    "    rec_data = calc_freq(rec_words)\n",
    "    not_rec_data = calc_freq(not_rec_words)\n",
    "\n",
    "    test = test_data.copy()\n",
    "\n",
    "    for index,row in test.iterrows():\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            if i not in rec_data: rec_data[i] = 0\n",
    "            if i not in not_rec_data: not_rec_data[i] = 0\n",
    "                \n",
    "    return rec_data,not_rec_data,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_smoothing(rec_data,not_rec_data):\n",
    "    rec = {}\n",
    "    not_rec = {}\n",
    "    for i in rec_data:\n",
    "        rec[i] = rec_data[i] + 1\n",
    "    for i in not_rec_data:\n",
    "        not_rec[i] = not_rec_data[i] + 1\n",
    "    return rec, not_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dict(dic):\n",
    "    sum = 0\n",
    "    for i in dic: \n",
    "        sum = sum + dic[i]\n",
    "    return sum\n",
    "\n",
    "def rec_or_not(test_,rec_data,not_rec_data,flag):\n",
    "    rec_words_count = sum_dict(rec_data)\n",
    "    not_rec_words_count = sum_dict(not_rec_data)\n",
    "    for index,row in test_.iterrows():\n",
    "        rec_prob = recommend_count/(recommend_count+not_recommend_count)\n",
    "        not_rec_prob = not_recommend_count/(recommend_count+not_recommend_count)\n",
    "        if flag == 1: temp = normalize_str(row['title'] + ' ' + row['comment'])\n",
    "        else: temp = word_tokenize(row['title'] + ' ' + row['comment'])\n",
    "        for i in temp:\n",
    "            rec_prob *= (rec_data[i]/rec_words_count)\n",
    "            not_rec_prob *= (not_rec_data[i]/not_rec_words_count)\n",
    "            if rec_prob >= not_rec_prob: row['recommend'] = 'recommended'\n",
    "            else: row['recommend'] = 'not_recommended'\n",
    "    return test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test):\n",
    "    wrong = []\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] : right += 1\n",
    "        else: wrong.append((test['title'][i],test['comment'][i],test['recommend'][i]))\n",
    "    return right/test.count()['title'],wrong\n",
    "\n",
    "def precision(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test[(test['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def recall(test):\n",
    "    right = 0\n",
    "    for i in range(test.count()['title']):\n",
    "        if test['recommend'][i] == test_data['recommend'][i] and test['recommend'][i] == 'recommended': right += 1\n",
    "    return right/(test_data[(test_data['recommend'] == 'recommended')].count()['title'])\n",
    "\n",
    "def f1(pre,rec):\n",
    "    return (2*pre*rec)/(pre+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process and additive smoothing:\n",
      "accuracy :  0.9175\n",
      "precision:  0.8938679245283019\n",
      "recall :  0.9475\n",
      "F1 :  0.9199029126213593\n"
     ]
    }
   ],
   "source": [
    "#pre process and additive smoothing\n",
    "rec_data_1,not_rec_data_1,test_1 = normalize_data(1)\n",
    "\n",
    "both_rec, both_not_rec = additive_smoothing(rec_data_1,not_rec_data_1)\n",
    "\n",
    "filled_test_both = rec_or_not(test_1,both_rec,both_not_rec,1)\n",
    "\n",
    "acc_1,wrong = accuracy(filled_test_both)\n",
    "prec_1 = precision(filled_test_both)\n",
    "rec_1 = recall(filled_test_both)\n",
    "f1_1 = f1(prec_1,rec_1)\n",
    "\n",
    "print(\"pre process and additive smoothing:\")\n",
    "print (\"accuracy : \",acc_1)\n",
    "print (\"precision: \",prec_1)\n",
    "print (\"recall : \",rec_1)\n",
    "print (\"F1 : \",f1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additive smoothing:\n",
      "accuracy :  0.91375\n",
      "precision:  0.8857808857808858\n",
      "recall :  0.95\n",
      "F1 :  0.916767189384801\n"
     ]
    }
   ],
   "source": [
    "#additive smoothing\n",
    "rec_data_2,not_rec_data_2,test_2 = normalize_data(0)\n",
    "\n",
    "additive_rec, additive_not_rec = additive_smoothing(rec_data_2,not_rec_data_2)\n",
    "\n",
    "filled_test_additive = rec_or_not(test_2,additive_rec,additive_not_rec,0)\n",
    "\n",
    "acc_2,r = accuracy(filled_test_additive)\n",
    "prec_2 = precision(filled_test_additive)\n",
    "rec_2 = recall(filled_test_additive)\n",
    "f1_2 = f1(prec_2,rec_2)\n",
    "\n",
    "print(\"additive smoothing:\")\n",
    "print (\"accuracy : \",acc_2)\n",
    "print (\"precision: \",prec_2)\n",
    "print (\"recall : \",rec_2)\n",
    "print (\"F1 : \",f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process:\n",
      "accuracy :  0.86\n",
      "precision:  0.7950819672131147\n",
      "recall :  0.97\n",
      "F1 :  0.8738738738738738\n"
     ]
    }
   ],
   "source": [
    "#pre process\n",
    "rec_data_3,not_rec_data_3,test_3 = normalize_data(1)\n",
    "\n",
    "filled_test_pre = rec_or_not(test_3,rec_data_3,not_rec_data_3,1)\n",
    "\n",
    "acc_3,r = accuracy(filled_test_pre)\n",
    "prec_3 = precision(filled_test_pre)\n",
    "rec_3 = recall(filled_test_pre)\n",
    "f1_3 = f1(prec_3,rec_3)\n",
    "\n",
    "print(\"pre process:\")\n",
    "print (\"accuracy : \",acc_3)\n",
    "print (\"precision: \",prec_3)\n",
    "print (\"recall : \",rec_3)\n",
    "print (\"F1 : \",f1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none:\n",
      "accuracy :  0.85625\n",
      "precision:  0.7844311377245509\n",
      "recall :  0.9825\n",
      "F1 :  0.872364039955605\n"
     ]
    }
   ],
   "source": [
    "#none\n",
    "rec_data_4,not_rec_data_4,test_4 = normalize_data(0)\n",
    "\n",
    "filled_test_none = rec_or_not(test_4,rec_data_4,not_rec_data_4,0)\n",
    "\n",
    "acc_4,r = accuracy(filled_test_none)\n",
    "prec_4 = precision(filled_test_none)\n",
    "rec_4 = recall(filled_test_none)\n",
    "f1_4 = f1(prec_4,rec_4)\n",
    "\n",
    "print(\"none:\")\n",
    "print (\"accuracy : \",acc_4)\n",
    "print (\"precision: \",prec_4)\n",
    "print (\"recall : \",rec_4)\n",
    "print (\"F1 : \",f1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وری گود</td>\n",
       "      <td>تازه خریدم یه مدت کار بکنه مشخص میشه کیفیت قطعاتش</td>\n",
       "      <td>not_recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دستگاه خیلی ضعیف</td>\n",
       "      <td>من این فیس براس چند روز یپش به دستم رسید و الا...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>خوب ولی کارایی محدود</td>\n",
       "      <td>مدل 46MM به دست شما نخواهد رسید و به جای آن مد...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نقد پس از خرید</td>\n",
       "      <td>سلام ، راحت شدم از کابل شارژ ، توصیه میشود به ...</td>\n",
       "      <td>not_recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نقد منصفانه</td>\n",
       "      <td>من تو تخفیف ویژه 5 تا خریدم و همشون رو هم تست ...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>عدم بسته بندی و تحویل مناسب</td>\n",
       "      <td>خیلی نردبان خوبیه خیلی بدرد بخوره تنها نکته من...</td>\n",
       "      <td>not_recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ظاهر خراب</td>\n",
       "      <td>شکل و ظاهر محصول که خیلی خط و خش داشت و پایینش...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>پیشنهاد نمیدم</td>\n",
       "      <td>من دوسه ماهی هست این کفشدازردیجی گرفتم متاسفان...</td>\n",
       "      <td>not_recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SanDisk</td>\n",
       "      <td>سلام وقتتون بخیر\\r\\nاولش که من این USB رو خرید...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>کلنیل</td>\n",
       "      <td>این نوعش به درد نمیخوره نوعش که گیاهیه خوبه.من...</td>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0                       وری گود   \n",
       "1              دستگاه خیلی ضعیف   \n",
       "2          خوب ولی کارایی محدود   \n",
       "3                نقد پس از خرید   \n",
       "4                   نقد منصفانه   \n",
       "..                          ...   \n",
       "61  عدم بسته بندی و تحویل مناسب   \n",
       "62                    ظاهر خراب   \n",
       "63                پیشنهاد نمیدم   \n",
       "64                      SanDisk   \n",
       "65                        کلنیل   \n",
       "\n",
       "                                              comment        recommend  \n",
       "0   تازه خریدم یه مدت کار بکنه مشخص میشه کیفیت قطعاتش  not_recommended  \n",
       "1   من این فیس براس چند روز یپش به دستم رسید و الا...      recommended  \n",
       "2   مدل 46MM به دست شما نخواهد رسید و به جای آن مد...      recommended  \n",
       "3   سلام ، راحت شدم از کابل شارژ ، توصیه میشود به ...  not_recommended  \n",
       "4   من تو تخفیف ویژه 5 تا خریدم و همشون رو هم تست ...      recommended  \n",
       "..                                                ...              ...  \n",
       "61  خیلی نردبان خوبیه خیلی بدرد بخوره تنها نکته من...  not_recommended  \n",
       "62  شکل و ظاهر محصول که خیلی خط و خش داشت و پایینش...      recommended  \n",
       "63  من دوسه ماهی هست این کفشدازردیجی گرفتم متاسفان...  not_recommended  \n",
       "64  سلام وقتتون بخیر\\r\\nاولش که من این USB رو خرید...      recommended  \n",
       "65  این نوعش به درد نمیخوره نوعش که گیاهیه خوبه.من...      recommended  \n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wrong, columns =['title', 'comment', 'recommend']) \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
